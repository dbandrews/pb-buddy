name: Scrape

on:
  schedule:
    - cron: "23 13,19,23 * * *"
  workflow_dispatch:

env:
  ACTIONS_ALLOW_UNSECURE_COMMANDS: true

jobs:
  scrape-latest:
    runs-on: ubuntu-latest

    steps:
      - name: Setup repo
        uses: actions/checkout@v2
      - name: Setup Conda env
        uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: pb-buddy
          environment-file: environment.yaml
          python-version: 3.8
          auto-activate-base: false
      - name: Set env vars
        run: |
          echo "DATE=$(python -c 'import datetime as dt; print((dt.datetime.now()))')" >> $GITHUB_ENV
      - name: Log env
        run: env
      - name: Run Scraper
        shell: bash -l {0}
        run: python scrape_base.py
        env: 
          COSMOS_CONN_STR : ${{secrets.COSMOS_CONN_STR}}
      - name: Email alerts
        shell: bash -l {0}
        run: python email_alerts.py
        env: 
          TWILIO_USER: ${{secrets.TWILIO_USER}}
          TWILIO_PASS: ${{secrets.TWILIO_PASS}}
          HOTMAIL_ADDRESS: ${{secrets.HOTMAIL_ADDRESS}}
      - name: Commit files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"        
          git add data/
          git add logs/
          git add alerts/
          git commit -m "Add data for $DATE"
      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: ${{ github.ref }}
